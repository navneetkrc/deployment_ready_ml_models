{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "keras-toxic-comment-classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navneetkrc/deployment_ready_ml_models/blob/master/keras_toxic_comment_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6jtVYWZmFK9",
        "colab_type": "text"
      },
      "source": [
        "# BentoML Example: Keras Toxic Comment Classification\n",
        "\n",
        "\n",
        "[BentoML](http://bentoml.ai) is an open source platform for machine learning model serving and deployment. \n",
        "\n",
        "This notebook demonstrates how to use BentoML to turn a Keras model into a docker image containing a REST API server serving this model, how to use your ML service built with BentoML as a CLI tool, and how to distribute it a pypi package.\n",
        "\n",
        "\n",
        "This notebook is built based on: https://www.kaggle.com/sarvajna/keras-sequential-model-lb-0-052\n",
        "\n",
        "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=keras&ea=keras-toxic-comment-classification&dt=keras-toxic-comment-classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQwCaFupPm6j",
        "colab_type": "text"
      },
      "source": [
        "Source  https://github.com/bentoml/BentoML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBZJLyk2mFLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LUC4fKamFLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bentoml\n",
        "!pip install keras kaggle tensorflow==1.14.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMvu_fKRmFLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bentoml\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp7CDjWZmFLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_of_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "max_features = 20000\n",
        "max_text_length = 400\n",
        "embedding_dims = 50\n",
        "filters = 250\n",
        "kernel_size = 3\n",
        "hidden_dims = 250\n",
        "batch_size = 32\n",
        "epochs = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asOA2LCDmFLc",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Dataset\n",
        "\n",
        "Please Download data with Kaggle at https://www.kaggle.com/sarvajna/keras-sequential-model-lb-0-052/data\n",
        "\n",
        "If you are running this notebook in Google Colab, fill in your kaggle credential below and download the training dataset from Kaggle:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1JSpt6Fs3ne",
        "colab_type": "code",
        "outputId": "3e6243aa-daa4-4fe3-a564-bb793352253a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQeK1RfGmFLd",
        "colab_type": "code",
        "outputId": "91350d06-d421-4cfc-c312-0db93e1b59f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!unzip '/content/drive/My Drive/MLAI_Datasets/jigsaw-toxic-comment-classification-challenge.zip'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/MLAI_Datasets/jigsaw-toxic-comment-classification-challenge.zip\n",
            "  inflating: sample_submission.csv.zip  \n",
            "  inflating: test.csv.zip            \n",
            "  inflating: test_labels.csv.zip     \n",
            "  inflating: train.csv.zip           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_4fmlj6taxw",
        "colab_type": "code",
        "outputId": "6a185bf1-9b79-4069-e6a8-cef8824c53b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!unzip train.csv.zip\n",
        "!unzip sample_submission.csv.zip\n",
        "!unzip test.csv.zip\n",
        "!unzip test_labels.csv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  test_labels.csv.zip\n",
            "  inflating: test_labels.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG5Ct9tCmFLi",
        "colab_type": "code",
        "outputId": "436dc400-cd81-4c62-f697-53a9309a7737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "train_df = pd.read_csv('./train.csv')\n",
        "\n",
        "print(train_df.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 id  ... identity_hate\n",
            "0  0000997932d777bf  ...             0\n",
            "1  000103f0d9cfb60f  ...             0\n",
            "2  000113f07ec002fd  ...             0\n",
            "3  0001b41b1c6bb37e  ...             0\n",
            "4  0001d958c54c6e35  ...             0\n",
            "\n",
            "[5 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OvDZTfNmFLm",
        "colab_type": "code",
        "outputId": "ced81e2b-a6ab-4ebf-979a-78275faa3ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "x = train_df['comment_text'].values\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\"\n",
            " \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\"\n",
            " \"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\"\n",
            " ...\n",
            " 'Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.'\n",
            " 'And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.'\n",
            " '\"\\nAnd ... I really don\\'t think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFxW7LEGmFLp",
        "colab_type": "code",
        "outputId": "b8f252e0-4534-4bfe-8b9f-87f5ead85101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y = train_df[list_of_classes].values\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " ...\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71snxE9ZmFLs",
        "colab_type": "code",
        "outputId": "85e05de4-e1d6-4975-a346-6176a2b69374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_tokenizer = text.Tokenizer(num_words=max_features)\n",
        "print(x_tokenizer)\n",
        "x_tokenizer.fit_on_texts(list(x))\n",
        "print(x_tokenizer)\n",
        "x_tokenized = x_tokenizer.texts_to_sequences(x) #list of lists(containing numbers), so basically a list of sequences, not a numpy array\n",
        "#pad_sequences:transform a list of num_samples sequences (lists of scalars) into a 2D Numpy array of shape \n",
        "x_train_val = sequence.pad_sequences(x_tokenized, maxlen=max_text_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras_preprocessing.text.Tokenizer object at 0x7f3e333f52e8>\n",
            "<keras_preprocessing.text.Tokenizer object at 0x7f3e333f52e8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AZV2uM3mFLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y, test_size=0.1, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nRU43VnmFL3",
        "colab_type": "code",
        "outputId": "da09caa1-8119-490d-83ff-f6f9677d7860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "print('Build model...')\n",
        "model = Sequential()\n",
        "\n",
        "# we start off with an efficient embedding layer which maps\n",
        "# our vocab indices into embedding_dims dimensions\n",
        "model.add(Embedding(max_features,\n",
        "                    embedding_dims,\n",
        "                    input_length=max_text_length))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# we add a Convolution1D, which will learn filters\n",
        "# word group filters of size filter_length:\n",
        "model.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "# we use max pooling:\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "# We add a vanilla hidden layer:\n",
        "model.add(Dense(hidden_dims))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# We project onto 6 output layers, and squash it with a sigmoid:\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 400, 50)           1000000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 400, 50)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 398, 250)          37750     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 250)               62750     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 1506      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 6)                 0         \n",
            "=================================================================\n",
            "Total params: 1,102,006\n",
            "Trainable params: 1,102,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShBw0YzVmFL6",
        "colab_type": "code",
        "outputId": "a2c30b8f-6209-4cda-ed2d-7fff7722c4df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 143613 samples, validate on 15958 samples\n",
            "Epoch 1/2\n",
            "143613/143613 [==============================] - 564s 4ms/step - loss: 0.0642 - acc: 0.9785 - val_loss: 0.0533 - val_acc: 0.9806\n",
            "Epoch 2/2\n",
            "143613/143613 [==============================] - 563s 4ms/step - loss: 0.0464 - acc: 0.9826 - val_loss: 0.0496 - val_acc: 0.9814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3e362c85c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpYsCz2SmFL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv('./test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH9DQBYXmFMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = test_df['comment_text'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlbrVv8ImFMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_tokenized = x_tokenizer.texts_to_sequences(x_test)\n",
        "x_testing = sequence.pad_sequences(x_test_tokenized, maxlen=max_text_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i7cH8eImFMJ",
        "colab_type": "code",
        "outputId": "42bc83a6-981d-4a36-b025-36332940d8e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_testing = model.predict(x_testing, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153164/153164 [==============================] - 132s 861us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAGzbRTzmFMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission = pd.read_csv(\"./sample_submission.csv\")\n",
        "sample_submission[list_of_classes] = y_testing\n",
        "sample_submission.to_csv(\"toxic_comment_classification.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUNbeRC4mFMR",
        "colab_type": "text"
      },
      "source": [
        "## Create BentoService for model serving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lifBPdowmFMS",
        "colab_type": "code",
        "outputId": "98ec5c38-4403-411b-ce87-1a2d5c5a9999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile toxic_comment_classifier.py\n",
        "\n",
        "from bentoml import api, artifacts, env, BentoService\n",
        "from bentoml.artifact import PickleArtifact, KerasModelArtifact\n",
        "from bentoml.handlers import DataframeHandler\n",
        "\n",
        "from keras.preprocessing import text, sequence\n",
        "import numpy as np\n",
        "\n",
        "list_of_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "max_text_length = 400\n",
        "\n",
        "@env(pip_dependencies=['tensorflow==1.14.0', 'keras', 'pandas', 'numpy'])\n",
        "@artifacts([PickleArtifact('x_tokenizer'), KerasModelArtifact('model')])\n",
        "class ToxicCommentClassification(BentoService):\n",
        "    \n",
        "    def tokenize_df(self, df):\n",
        "        comments = df['comment_text'].values\n",
        "        tokenized = self.artifacts.x_tokenizer.texts_to_sequences(comments)        \n",
        "        input_data = sequence.pad_sequences(tokenized, maxlen=max_text_length)\n",
        "        return input_data\n",
        "    \n",
        "    @api(DataframeHandler)\n",
        "    def predict(self, df):\n",
        "        input_data = self.tokenize_df(df)\n",
        "        prediction = self.artifacts.model.predict(input_data)\n",
        "        result = []\n",
        "        for i in prediction:\n",
        "            result.append(list_of_classes[np.argmax(i)])\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting toxic_comment_classifier.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dcnu9y1mFMU",
        "colab_type": "text"
      },
      "source": [
        "## Save BentoService to file archive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IkhYOsedmFMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1) import the custom BentoService defined above\n",
        "from toxic_comment_classifier import ToxicCommentClassification\n",
        "\n",
        "# 2) `pack` it with required artifacts\n",
        "svc = ToxicCommentClassification()\n",
        "svc.pack('x_tokenizer', x_tokenizer)\n",
        "svc.pack('model', model)\n",
        "\n",
        "# 3) save your BentoSerivce\n",
        "saved_path = svc.save()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXhq7yXJmFMX",
        "colab_type": "text"
      },
      "source": [
        "## Load BentoService from archive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPMZ5529mFMY",
        "colab_type": "code",
        "outputId": "f07d62c5-d6ad-4202-c9d6-6d44485aaf99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "sample_test = test_df.iloc[40:42]\n",
        "print(sample_test)\n",
        "bento_service = bentoml.load(saved_path)\n",
        "\n",
        "print(bento_service.predict(sample_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  id                                       comment_text\n",
            "40  0011cefc680993ba                      REDIRECT Talk:Mi Vida Eres Tú\n",
            "41  0011ef6aa33d42e6  \" \\n I'm not convinced that he was blind. Wher...\n",
            "['toxic', 'toxic']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSw9BWx9mFMc",
        "colab_type": "code",
        "outputId": "57aeddf0-70f4-4182-af97-ed98a5e5024d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#Need to store these services name such that we can easily use them for the cells that follow\n",
        "!bentoml get ToxicCommentClassification"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[39mBENTO_SERVICE                                     AGE                           APIS                       ARTIFACTS\n",
            "ToxicCommentClassification:20200214093630_7EDBFF  44 minutes and 21.78 seconds  predict<DataframeHandler>  x_tokenizer<PickleArtifact>, model<KerasModelArtifact>\n",
            "ToxicCommentClassification:20200214082616_B70B48  1 hour and 54 minutes         predict<DataframeHandler>  x_tokenizer<PickleArtifact>, model<KerasModelArtifact>\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG3QYVIumFMf",
        "colab_type": "code",
        "outputId": "eb6a3ea7-a35b-4d9a-c68e-0c96099bec9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "!bentoml get ToxicCommentClassification:20200214093630_7EDBFF "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[39m{\n",
            "  \"name\": \"ToxicCommentClassification\",\n",
            "  \"version\": \"20200214093630_7EDBFF\",\n",
            "  \"uri\": {\n",
            "    \"type\": \"LOCAL\",\n",
            "    \"uri\": \"/root/bentoml/repository/ToxicCommentClassification/20200214093630_7EDBFF\"\n",
            "  },\n",
            "  \"bentoServiceMetadata\": {\n",
            "    \"name\": \"ToxicCommentClassification\",\n",
            "    \"version\": \"20200214093630_7EDBFF\",\n",
            "    \"createdAt\": \"2020-02-14T09:36:56.615243Z\",\n",
            "    \"env\": {\n",
            "      \"condaEnv\": \"name: bentoml-ToxicCommentClassification\\nchannels:\\n- defaults\\ndependencies:\\n- python=3.6.9\\n- pip\\n\",\n",
            "      \"pipDependencies\": \"bentoml==0.6.2\\ntensorflow==1.14.0\\nkeras\\npandas\\nnumpy\",\n",
            "      \"pythonVersion\": \"3.6.9\"\n",
            "    },\n",
            "    \"artifacts\": [\n",
            "      {\n",
            "        \"name\": \"x_tokenizer\",\n",
            "        \"artifactType\": \"PickleArtifact\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"model\",\n",
            "        \"artifactType\": \"KerasModelArtifact\"\n",
            "      }\n",
            "    ],\n",
            "    \"apis\": [\n",
            "      {\n",
            "        \"name\": \"predict\",\n",
            "        \"handlerType\": \"DataframeHandler\",\n",
            "        \"docs\": \"BentoService API\",\n",
            "        \"handlerConfig\": {\n",
            "          \"orient\": \"records\",\n",
            "          \"typ\": \"frame\",\n",
            "          \"input_dtypes\": null,\n",
            "          \"output_orient\": \"records\"\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md6ggLBYmFMi",
        "colab_type": "code",
        "outputId": "6e260747-57ee-4e71-b1a6-9e08e0e197a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "!bentoml info ToxicCommentClassification:20200214093630_7EDBFF "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[39m{\n",
            "  \"name\": \"ToxicCommentClassification\",\n",
            "  \"version\": \"20200214093630_7EDBFF\",\n",
            "  \"created_at\": \"2020-02-14T09:36:56.615243Z\",\n",
            "  \"env\": {\n",
            "    \"conda_env\": \"name: bentoml-ToxicCommentClassification\\nchannels:\\n- defaults\\ndependencies:\\n- python=3.6.9\\n- pip\\n\",\n",
            "    \"pip_dependencies\": \"bentoml==0.6.2\\ntensorflow==1.14.0\\nkeras\\npandas\\nnumpy\",\n",
            "    \"python_version\": \"3.6.9\"\n",
            "  },\n",
            "  \"artifacts\": [\n",
            "    {\n",
            "      \"name\": \"x_tokenizer\",\n",
            "      \"artifact_type\": \"PickleArtifact\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"model\",\n",
            "      \"artifact_type\": \"KerasModelArtifact\"\n",
            "    }\n",
            "  ],\n",
            "  \"apis\": [\n",
            "    {\n",
            "      \"name\": \"predict\",\n",
            "      \"handler_type\": \"DataframeHandler\",\n",
            "      \"docs\": \"BentoService API\",\n",
            "      \"handler_config\": {\n",
            "        \"orient\": \"records\",\n",
            "        \"typ\": \"frame\",\n",
            "        \"input_dtypes\": null,\n",
            "        \"output_orient\": \"records\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00Iad07UmFMm",
        "colab_type": "code",
        "outputId": "b2cbb812-5a6c-4f77-ccc6-c1073028ee60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!bentoml run ToxicCommentClassification:20200213141504_137C94 predict --input '[{\"comment_text\": \"bad terrible\"}]'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/bentoml\", line 8, in <module>\n",
            "    sys.exit(cli())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 764, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 717, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 1137, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 956, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 555, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bentoml/cli/click_utils.py\", line 94, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bentoml/cli/__init__.py\", line 146, in run\n",
            "    bento, pip_installed_bundle_path\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bentoml/cli/__init__.py\", line 117, in resolve_bundle_path\n",
            "    f'BentoService {name}:{version} not found - '\n",
            "bentoml.exceptions.BentoMLException: BentoService ToxicCommentClassification:20200213141504_137C94 not found - NOT_FOUND:BentoService `ToxicCommentClassification:20200213141504_137C94` is not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYo73441mFMp",
        "colab_type": "text"
      },
      "source": [
        "## Use BentoService as PyPI package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwf4D40EmFMq",
        "colab_type": "code",
        "outputId": "e24beab1-87cd-44c6-b390-998f7c169b7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install {saved_path}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /root/bentoml/repository/ToxicCommentClassification/20200214093630_7EDBFF\n",
            "Requirement already satisfied: bentoml==0.6.2 in /usr/local/lib/python3.6/dist-packages (from ToxicCommentClassification===20200214093630-7EDBFF) (0.6.2)\n",
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (from ToxicCommentClassification===20200214093630-7EDBFF) (1.14.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from ToxicCommentClassification===20200214093630-7EDBFF) (2.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ToxicCommentClassification===20200214093630-7EDBFF) (0.25.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ToxicCommentClassification===20200214093630-7EDBFF) (1.17.5)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (20.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (1.3.13)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (0.8.6)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (0.1.11)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (4.0.2)\n",
            "Requirement already satisfied: cerberus in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (1.3.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (7.0)\n",
            "Requirement already satisfied: humanfriendly in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (6.1)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (1.4.0)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (1.27.1)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1 in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (2.6.1)\n",
            "Requirement already satisfied: gunicorn in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (20.0.4)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (0.7.1)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (4.2.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (1.11.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (2.21.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (0.16.10)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->ToxicCommentClassification===20200214093630-7EDBFF) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->ToxicCommentClassification===20200214093630-7EDBFF) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->ToxicCommentClassification===20200214093630-7EDBFF) (0.1.8)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->ToxicCommentClassification===20200214093630-7EDBFF) (1.14.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->ToxicCommentClassification===20200214093630-7EDBFF) (1.14.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->ToxicCommentClassification===20200214093630-7EDBFF) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->ToxicCommentClassification===20200214093630-7EDBFF) (1.11.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->ToxicCommentClassification===20200214093630-7EDBFF) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->ToxicCommentClassification===20200214093630-7EDBFF) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->ToxicCommentClassification===20200214093630-7EDBFF) (0.9.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->ToxicCommentClassification===20200214093630-7EDBFF) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->ToxicCommentClassification===20200214093630-7EDBFF) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->ToxicCommentClassification===20200214093630-7EDBFF) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->ToxicCommentClassification===20200214093630-7EDBFF) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->ToxicCommentClassification===20200214093630-7EDBFF) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->ToxicCommentClassification===20200214093630-7EDBFF) (2018.9)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (1.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (2.11.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (1.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (2.4.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from cerberus->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (45.1.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.6/dist-packages (from alembic->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (1.1.1)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (1.0.4)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from docker->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (0.57.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.14 in /usr/local/lib/python3.6/dist-packages (from boto3->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (1.14.14)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (0.3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (2.8)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from ruamel.yaml>=0.15.0->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (0.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->ToxicCommentClassification===20200214093630-7EDBFF) (3.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (1.1.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.14->boto3->bentoml==0.6.2->ToxicCommentClassification===20200214093630-7EDBFF) (0.15.2)\n",
            "Building wheels for collected packages: ToxicCommentClassification\n",
            "  Building wheel for ToxicCommentClassification (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ToxicCommentClassification: filename=ToxicCommentClassification-20200214093630_7EDBFF-cp36-none-any.whl size=16002720 sha256=9adb7bab7a011f29a501f413d486cc74bba039082f98dfced5dc1c7ae23300f1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gwziowqr/wheels/01/51/03/74062e09c52acb297c2ed760b536388f4f0bed198c40f59266\n",
            "Successfully built ToxicCommentClassification\n",
            "Installing collected packages: ToxicCommentClassification\n",
            "  Found existing installation: ToxicCommentClassification 20200214082616-B70B48\n",
            "    Uninstalling ToxicCommentClassification-20200214082616-B70B48:\n",
            "      Successfully uninstalled ToxicCommentClassification-20200214082616-B70B48\n",
            "Successfully installed ToxicCommentClassification-20200214093630-7EDBFF\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ToxicCommentClassification"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-VG8vtbmFMt",
        "colab_type": "code",
        "outputId": "fd60c135-c4c8-408c-e50d-9bd14f30437d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import ToxicCommentClassification\n",
        "\n",
        "svc = ToxicCommentClassification.load()\n",
        "result = svc.predict(sample_test)\n",
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['toxic', 'toxic']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN_HWAo5mFMy",
        "colab_type": "text"
      },
      "source": [
        "## Deploy BentoService as REST API server to the cloud\n",
        "\n",
        "\n",
        "BentoML support deployment to multiply cloud provider services, such as AWS Lambda, AWS Sagemaker, Google Cloudrun and etc. You can find the full list and guide on the documentation site at https://docs.bentoml.org/en/latest/deployment/index.html\n",
        "\n",
        "For this project, we are going to deploy to AWS Sagemaker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJfW-m96mFMz",
        "colab_type": "text"
      },
      "source": [
        "**Use `bentoml sagemaker deploy` to deploy BentoService to AWS Sagemaker**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjiglkS3mFM0",
        "colab_type": "code",
        "outputId": "da02f372-6272-4ede-e81c-7ca11b036acf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "!bentoml sagemaker deploy keras-toxic -b ToxicCommentClassification:20200214093630_7EDBFF \\\n",
        "    --api-name predict --verbose"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-02-14 10:23:09,161] DEBUG - Using BentoML with local Yatai server\n",
            "[2020-02-14 10:23:09,285] DEBUG - Upgrading tables to the latest revision\n",
            "\u001b[31mFailed to create AWS Sagemaker deployment keras-toxic.: Deployment \"keras-toxic\" already existed, use Update or Apply for updating existing deployment, delete the deployment, or use a different deployment name\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc--ncG3mFM2",
        "colab_type": "text"
      },
      "source": [
        "`bentoml sagemaker list` displays all deployed Sagemaker deployments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DtfmRKcmFM2",
        "colab_type": "code",
        "outputId": "df391a79-bf1e-43b4-ed7f-1acd7c974dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!bentoml sagemaker list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[39mNAME         NAMESPACE    PLATFORM       BENTO_SERVICE                                     STATUS    AGE\n",
            "keras-toxic  dev          aws-sagemaker  ToxicCommentClassification:20200213141504_137C94  pending   1 hour and 55 minutes\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBJHYyjhmFM5",
        "colab_type": "text"
      },
      "source": [
        "`bentoml sagemaker get` retrieve the latest status of Sagemaker deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGjstQQrmFM6",
        "colab_type": "code",
        "outputId": "9dfe9832-4227-435c-90e5-ff9f93c3f146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "!bentoml sagemaker get keras-toxic"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/bentoml\", line 8, in <module>\n",
            "    sys.exit(cli())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 764, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 717, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 1137, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 1137, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 956, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 555, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bentoml/cli/click_utils.py\", line 94, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bentoml/cli/aws_sagemaker.py\", line 352, in get\n",
            "    describe_result = yatai_client.deployment.describe(namespace, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bentoml/yatai/client/deployment_api.py\", line 103, in describe\n",
            "    DescribeDeploymentRequest(deployment_name=name, namespace=namespace)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bentoml/yatai/yatai_service_impl.py\", line 225, in DescribeDeployment\n",
            "    response = operator.describe(deployment_pb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bentoml/deployment/sagemaker/__init__.py\", line 720, in describe\n",
            "    sagemaker_config.region or get_default_aws_region()\n",
            "TypeError: None has type NoneType, but expected one of: bytes, unicode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdYocqvmmFM9",
        "colab_type": "text"
      },
      "source": [
        "Validate and test Sagemaker deployment with sample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_PpqRY8mFM-",
        "colab_type": "code",
        "outputId": "36d396fa-f653-4e62-eb81-57b8472d2680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!aws sagemaker-runtime invoke-endpoint --endpoint-name bobo-keras-toxic \\\n",
        "--body '[{\"comment_text\": \"bad terrible\"}]' --content-type application/json output.json && cat output.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: aws: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT7pQFOMmFNA",
        "colab_type": "text"
      },
      "source": [
        "`bentoml sagemaker delete` will remove Sagmaker deployment and related resources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emm3UjovmFNC",
        "colab_type": "code",
        "outputId": "e33448c5-6de7-42d9-e9bd-5e2c302691ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "!bentoml sagemaker delete keras-toxic"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/bentoml\", line 8, in <module>\n",
            "    sys.exit(cli())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 764, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 717, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 1137, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 1137, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 956, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/click/core.py\", line 555, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bentoml/cli/click_utils.py\", line 94, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bentoml/cli/aws_sagemaker.py\", line 295, in delete\n",
            "    result = yatai_client.deployment.delete(name, namespace, force)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bentoml/yatai/client/deployment_api.py\", line 111, in delete\n",
            "    force_delete=force_delete,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bentoml/yatai/yatai_service_impl.py\", line 151, in DeleteDeployment\n",
            "    response = operator.delete(deployment_pb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bentoml/deployment/sagemaker/__init__.py\", line 704, in delete\n",
            "    sagemaker_config.region or get_default_aws_region()\n",
            "TypeError: None has type NoneType, but expected one of: bytes, unicode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2yyhTqEOc1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}